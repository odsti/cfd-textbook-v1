{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46e6ef4",
   "metadata": {},
   "source": [
    "# Lady tasting tea\n",
    "\n",
    "In this page, we analyze the famous experiment of the [lady tasting\n",
    "tea](https://en.wikipedia.org/wiki/Lady_tasting_tea).\n",
    "\n",
    "This is an experiment discussed by [Ronald\n",
    "Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) and\n",
    "\n",
    "> ... loosely based on an event in Fisher's life. The lady in question,\n",
    "> Muriel Bristol, claimed to be able to tell whether the tea or the milk\n",
    "> was added first to a cup. Her future husband, William Roach, suggested\n",
    "> that Fisher give her eight cups, four of each variety, in random\n",
    "> order. One could then ask what the probability was for her getting the\n",
    "> specific number of cups she identified correct (in fact all eight),\n",
    "> but just by chance.\n",
    ">\n",
    "> ...\n",
    ">\n",
    "> The experiment provides a subject with eight randomly ordered cups of\n",
    "> tea – four prepared by pouring milk and then tea, four by pouring tea\n",
    "> and then milk. The subject attempts to select the four cups prepared\n",
    "> by one method or the other, and may compare cups directly against each\n",
    "> other as desired.\n",
    "\n",
    "In fact, Muriel Bristol was able to correctly identify the four cups of tea for\n",
    "which milk had been poured before the tea.\n",
    "\n",
    "Fisher's write-up of this experiment and his proposed analysis, was the first\n",
    "time he proposed the idea of the *null hypothesis*.\n",
    "\n",
    "As you remember, the null hypothesis — or null model — is a model of the world\n",
    "that is as close as possible to the real world, but having set the effect you\n",
    "are interested in to be 0 (null).\n",
    "\n",
    "In this case, the null model is that Muriel Bristol was in general\n",
    "unable to distinguish the milk-first tea from the milk-second tea, and\n",
    "was therefore choosing cups at chance.\n",
    "\n",
    "Let us build something like the data the Fisher had, and see how we can do our\n",
    "test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cec889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A numpy random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "import pandas as pd\n",
    "# Safe setting for Pandas.  Needs Pandas version >= 1.5.\n",
    "pd.set_option('mode.copy_on_write', True)\n",
    "\n",
    "# Load the library for plotting, name it 'plt'\n",
    "import matplotlib.pyplot as plt\n",
    "# Make plots look a little more fancy\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021238a2",
   "metadata": {},
   "source": [
    "We'll build a data table similar to the one that Fisher would have been looking at when he did his analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1341fb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Just run the code in this cell.\n",
    "# Make an empty DataFrame to store the eight cups.\n",
    "tea_df = pd.DataFrame()\n",
    "# insert a column that records whether Fisher had in fact poured the milk\n",
    "# before the tea, into that cup:\n",
    "tea_df['milk_first'] = np.repeat(['yes', 'no'], [4, 4])\n",
    "# Add a column recording which cups Muriel chose as her guesses for the\n",
    "# cups where Fisher had poured the milk first:\n",
    "tea_df['says_milk_first'] = np.repeat(['yes', 'no'], [4, 4])\n",
    "# Take a sample (without replacement) of 8 rows.\n",
    "# This has the effect of putting rows in random order.\n",
    "tea_df = tea_df.sample(8, replace=False)\n",
    "# Reset the row labels to throw away the labels showing the original order.\n",
    "tea_df = tea_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4208b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our reconstruction of Fisher's table\n",
    "tea_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfebd28",
   "metadata": {},
   "source": [
    "Now we have something like the experimental data — the actual situation\n",
    "(`milk_first`) and Muriel's identification `says_milk_first`.\n",
    "\n",
    "We fetch the two columns back out of the data frame as two Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0663f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk_first = tea_df['milk_first']\n",
    "says_milk_first = tea_df['says_milk_first']\n",
    "says_milk_first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00043219",
   "metadata": {},
   "source": [
    "It is often useful to cross-tabulate the rows of the data frame by giving\n",
    "counts in each category. [pd.crosstab](crosstab) does this\n",
    "job, given the two columns of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tab = pd.crosstab(milk_first, says_milk_first)\n",
    "counts_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd725dcc",
   "metadata": {},
   "source": [
    "Notice that the cross-tabulation counts the number of rows (observations) in\n",
    "each of the four possible categories:\n",
    "\n",
    "* Actually milk-first, Muriel says milk-first ('yes', 'yes' rows).\n",
    "* Actually milk-second, Muriel says milk-first ('no', 'yes' rows).\n",
    "* Actually milk-first, Muriel says milk-second ('yes', 'no' rows).\n",
    "* Actually milk-second, Muriel says milk-second ('no', 'no', rows).\n",
    "\n",
    "We will concentrate on the 'yes', 'yes' combination.  If Muriel correctly\n",
    "identifies all four of the milk-first cups, that means she got every cup\n",
    "correct — because she must identify four as milk-first, and four as tea-first.\n",
    "\n",
    "In other words, if she got all milk-first cups right ('yes', 'yes'), then she necessarily got all four tea-first cups right ('no', 'no')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ff249",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk_first_correct = counts_tab.loc['yes', 'yes']\n",
    "milk_first_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9969f",
   "metadata": {},
   "source": [
    "As we know, in fact, Muriel guessed correctly for each of the eight\n",
    "cups, and so correctly identified all four milk-first cups.\n",
    "\n",
    "Now our question is — how would we decide if this could reasonably have come\n",
    "about by chance?  This is the question we answer with *inference*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc38f3c",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Remember the [steps in inference](inference).\n",
    "\n",
    "* Find the **data**. In our case, these are the data in `tea_df` DataFrame.\n",
    "* Calculate some **measure of interest** from the data.  Call this the\n",
    "  **observed statistic**.  Let us use the number of milk-first cups that Muriel identified: `milk_first_correct` above.\n",
    "* Make a simple null-model of the world to offer as an explanation of the data.\n",
    "  In our null-world, Muriel has no ability to distinguish milk-first from\n",
    "  milk-second cups, and is therefore guessing when choosing her four cups.\n",
    "* **Simulate the data** many times using the simple (null-world) model.\n",
    "* For each simulation **calculate the measure of interest**.  Call these the\n",
    "  **simulated measures**.  Our simulated measures were the number of black\n",
    "  jurors in each simulation.\n",
    "* Use the **simulated measures** to build up the **sampling distribution**.\n",
    "* Compare the **observed measure** to the **sampling distribution**, to see\n",
    "  whether it represents a rare or common event, given the model.\n",
    "\n",
    "Our remaining work is to build the null-world model, in which we do the\n",
    "simulations.\n",
    "\n",
    "The experiment requires that Muriel chose four cups.  So we always have four\n",
    "'yes' votes and four 'no' votes.\n",
    "\n",
    "How can we simulate our null-world, where Muriel is distributing her four 'yes' and four 'no' replies randomly across the cups?\n",
    "\n",
    "If those votes are random, that is the same thing as saying that Muriel's votes\n",
    "could be in any random order.\n",
    "\n",
    "This gives us an idea for a single trial of eight cups in the null world.  First we shuffle Muriel's replies into a random order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the random association.\n",
    "fake_says = rng.permutation(says_milk_first)\n",
    "fake_says"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38b81e",
   "metadata": {},
   "source": [
    "Then we rebuild the counts table *but with the random ordering of replies*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with the random ordering of replies.\n",
    "fake_counts_tab = pd.crosstab(milk_first, fake_says)\n",
    "fake_counts_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5988d94",
   "metadata": {},
   "source": [
    "Then we look at the count we got for 'yes', 'yes' with this fake ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mf_correct = fake_counts_tab.loc['yes', 'yes']\n",
    "fake_mf_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994de24",
   "metadata": {},
   "source": [
    "Now we know how to do one trial, we can extend to thousands of trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we're only using 1000 iterations, not our usual 10_000\n",
    "# This is to save some time; the crosstab is a little slow.\n",
    "n_iters = 1000\n",
    "fake_mf_corrects = np.zeros(n_iters)\n",
    "for i in np.arange(n_iters):\n",
    "    fake_says = rng.permutation(says_milk_first)\n",
    "    fake_counts_tab = pd.crosstab(milk_first, fake_says)\n",
    "    fake_mf_correct = fake_counts_tab.loc['yes', 'yes']\n",
    "    fake_mf_corrects[i] = fake_mf_correct\n",
    "fake_mf_corrects[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352df1a",
   "metadata": {},
   "source": [
    "Each value in the 1000 `fake_mf_corrects` array is a 'yes', 'yes' count that\n",
    "we saw in a particular trial in the null world, where Muriel was choosing the\n",
    "four cups at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fake_mf_corrects, bins=np.arange(5));\n",
    "plt.title('Sampling distribution of yes, yes counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97249022",
   "metadata": {},
   "source": [
    "The result in the real world was that Muriel identified all four milk-first\n",
    "('yes') cups, and therefore, chose correctly in all 8 cases. How likely is\n",
    "that result, in our null world (null model)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(fake_mf_corrects == 4) / n_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25647ed3",
   "metadata": {},
   "source": [
    "The result in the real world was surprising, if the null model was correct.\n",
    "We may therefore choose to provisionally reject the null model, and suspect\n",
    "that there was some deviation from the null model — for example, that Muriel\n",
    "was in fact able to do better than chance in detecting the milk-first cups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a20ce",
   "metadata": {},
   "source": [
    "## Fisher's exact test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08ba44",
   "metadata": {},
   "source": [
    "In fact, Fisher used an almost identical method to solve the problem in his original description.\n",
    "\n",
    "His method differs only in that, instead of trying lots of different random\n",
    "permutations of the pairings, he used a mathematical method to work out:\n",
    "\n",
    "* how many *possible permutations* there are, and\n",
    "* how many of these possible permutations give a value as great or greater\n",
    "than the value we observe.\n",
    "\n",
    "In this case, that problem is fairly easy to solve, because there is only one\n",
    "way that we can end up with 4 out of 4 'yes', 'yes' answers (all correct).\n",
    "\n",
    "To start, there are 4 cups.  Muriel has a 4/8 chance of selecting the correct\n",
    "cup.\n",
    "\n",
    "Next time round, there are seven cups, three with milk-first; she has\n",
    "a 3 / 7 chance.\n",
    "\n",
    "For her four choices then, we have the following four chances, applied one\n",
    "after the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability that Muriel will select all 4 milk-first cups\n",
    "# correctly if she is just guessing.\n",
    "4 / 8 * 3 / 7 * 2 / 6 * 1 / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd0f4e",
   "metadata": {},
   "source": [
    "This turns out to be one chance in 70.  There are 70 possible unique\n",
    "permutations of the milk-first `yes`, `no` and Muriel's guesses, of which only\n",
    "one gives all 4 `yes`, `yes` correct.\n",
    "`no`, `no`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd755bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4eee90",
   "metadata": {},
   "source": [
    "We can generalize this technique of counting all possible permutations, and\n",
    "dividing into the number of permutations giving a value equal or greater than\n",
    "the one we observe.  The method is called Fisher's Exact test, after Fisher's\n",
    "first description, with the Lady Tasting Tea problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ac073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stats module from Scipy.\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b812fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Fisher's Exact Test p-value\n",
    "odds_ratio, p_value = sps.fisher_exact(counts_tab,\n",
    "                                       alternative='greater')\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da6d09",
   "metadata": {},
   "source": [
    "As you can see, Fisher's Exact Test gives a very similar p-value to the one we\n",
    "got from random permutations, and exactly the 1 / 70 value we worked out\n",
    "above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f9ba1",
   "metadata": {},
   "source": [
    "## One-tailed and two-tailed alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68bdf3",
   "metadata": {},
   "source": [
    "Notice the `alternative='greater'` argument to the function.  This tells the\n",
    "routine to look for all permutations that give *top-left* value that is\n",
    "greater than, or equal to, the top-left value of the `counts_tab` we passed.\n",
    "\n",
    "**Note** - the top-left value is the count for `no` and `no`, and we were actually interested in the *bottom-right* value (`yes`, `yes`), but because of the [way that 2 by 2 tables work](two_by_two_tables.Rmd), this is the same as doing the test on the top-left value.  Put another way, the routine tests the `no`, `no` value, but if Muriel gets all the `yes` cups right (`yes`, `yes`), she must also get all the `no` cups right (`no`, `no`).\n",
    "\n",
    "In our case, we do want to do the `alternative='greater'` test, because we are only interested in whether Muriel can do *better* than chance - not whether she can do *worse* than chance.\n",
    "\n",
    "Put another way, our alternative to the null-hypothesis, is that Muriel can do *better than* chance.\n",
    "\n",
    "But you could imagine other situations where you are looking more generally for signs that the table shows some deviation from chance, and in that case, you might also consider the situation where Muriel systematically said `no` to the `yes` cups, and `yes` to the `no` cups.  In that case, you would be interested in *either* of a very high value for `no`, `no` (4 - the actual result), or a very low value for `no`, `no` (0 - the result if Muriel was getting it systematically and invariably wrong).\n",
    "\n",
    "If we are prepared to consider *either* a low value or a high value as evidence against the null-hypothesis, then our *altnerative* hypothesis is that Muriel is *either* doing better than chance *or* worse than chance.  We will accept evidence for either of these cases as evidence against the null-hypothesis, of Muriel guessing at random.\n",
    "\n",
    "In that case, we call this a *two-tailed alternative*.  In contrast, our original test was *one-tailed* because we were only considering the high value (the high *tail*) as interesting.\n",
    "\n",
    "If you allow both high and low values to be interesting, then there are two interesting permutations of the 70 unique permutations, the `no`, `no` = 4 permutation and the `no`, `no` = 0 permutation, and the probability value of seeing either of these permutations, for any given random permutation, is twice as large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 / 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30151274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-tailed alternative, p-value.\n",
    "t2_odds_ratio, t2_p_value = sps.fisher_exact(counts_tab,\n",
    "                                            alternative='two-sided')\n",
    "t2_p_value"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  },
  "orphan": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
