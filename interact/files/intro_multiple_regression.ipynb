{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b07ec36",
   "metadata": {},
   "source": [
    "# Simple and multiple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0965a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Safe setting for Pandas.  Needs Pandas version >= 1.5.\n",
    "pd.set_option('mode.copy_on_write', True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fff87",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# For calculating correlation\n",
    "def standard_units(any_numbers):\n",
    "    \"\"\" Convert any array of numbers to standard units.\n",
    "    \"\"\"\n",
    "    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)\n",
    "\n",
    "def correlation(t, x, y):\n",
    "    \"\"\" Correlation of columns `x` and `y` from data frame `t`\n",
    "    \"\"\"\n",
    "    return np.mean(standard_units(t[x]) * standard_units(t[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581de576",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def scatter_errors(x_values, y_values, c, s):\n",
    "    \"\"\" Plot a line through data with errors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_values : array\n",
    "        Values we are predicting from, for the x-axis of the plot.\n",
    "    y_values : array\n",
    "        Values we are predicting, for the y-axis of the plot.\n",
    "    c : number\n",
    "        Intercept for predicting line.\n",
    "    s : number\n",
    "        Slope for predicting line.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmse : number\n",
    "        The square root of the mean squared error, for the given `x_values`,\n",
    "        `y_values` and line.\n",
    "    \"\"\"\n",
    "    # Predict the y values from the line.\n",
    "    predicted = c + s * x_values\n",
    "    # Errors are the real values minus the predicted values.\n",
    "    errors = y_values - predicted\n",
    "    # Plot real values in blue, predicted values in red.\n",
    "    actual_points = plt.plot(x_values, y_values, 'o', color='blue')\n",
    "    predicted_points = plt.plot(x_values, predicted, 'o', color='red')\n",
    "    # Draw a line between predicted and actual\n",
    "    for i in np.arange(len(x_values)):\n",
    "        x = x_values[i]\n",
    "        y_0 = predicted[i]\n",
    "        y_1 = y_values[i]\n",
    "        error_line = plt.plot([x, x], [y_0, y_1], ':', color='black', linewidth=1)\n",
    "    plt.legend(actual_points + predicted_points + error_line,\n",
    "               ['Actual', 'Predicted', 'Error'])\n",
    "    return np.sqrt(np.mean(errors ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2153501",
   "metadata": {},
   "source": [
    "## Simple and multiple regression\n",
    "\n",
    "We looked at simple regression in the [finding\n",
    "lines](finding_lines) page, and those following.\n",
    "\n",
    "Simple regression uses a single set of predictor values, and a straight line,\n",
    "to predict another set of values.\n",
    "\n",
    "For example, in the finding lines page above, we predicted the \"quality\" scores\n",
    "(on the y-axis) from the \"easiness\" scores (on the x-axis).\n",
    "\n",
    "This page is about *multiple regression*.  Multiple regression takes simple\n",
    "regression a step further.  Now we use more than one set of values to predict\n",
    "another set of values.\n",
    "\n",
    "On the way, we will start using a standard statistics library in Python, called\n",
    "StatsModels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050580d1",
   "metadata": {},
   "source": [
    "## Simple regression\n",
    "\n",
    "Let us return to simple regression â€” using one set of values (on the x axis) to\n",
    "predict another set of values (on the y axis).\n",
    "\n",
    "Here is our familiar [chronic kidney disease\n",
    "dataset](data/chronic_kidney_disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5473344",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd = pd.read_csv('data/ckd_clean.csv')\n",
    "ckd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74cce2",
   "metadata": {},
   "source": [
    "In our case, we restrict ourselves to the chronic kidney disease patients.\n",
    "These patients have a `1` in the `Class` column.\n",
    "\n",
    "We're also going to restrict ourselves to looking at the following measures:\n",
    "\n",
    "* `Serum Creatinine`: a measure of how well the kidney is clearing substances\n",
    "  from the blood.  When creatinine is high, it means the kidney is not clearing\n",
    "  well.  This is the general measure of kidney disease that we are interested\n",
    "  to predict.\n",
    "* `Blood Urea`: another measure of the ability of the kidney to clear\n",
    "  substances from the blood.  Urea is high in the blood when the kidneys are\n",
    "  not clearing efficiently.\n",
    "* `Hemoglobin`: healthy kidneys release a hormone *erythropoietin* that\n",
    "  stimulates production of red blood cells, and red blood cells contain the\n",
    "  *hemoglobin* molecule.  When the kidneys are damaged, they produce less\n",
    "  erythropoietin, so the body produces fewer red blood cells, and there is a\n",
    "  lower concentration of hemoglobin in the blood.\n",
    "* `White Blood Cell Count`: white cells are the immune cells in the blood.\n",
    "  White cells increase in number when there is some inflammatory process in the\n",
    "  body.  There is [some\n",
    "  dispute](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0052775)\n",
    "  about whether the white blood cell count is a useful measure in chronic\n",
    "  kidney disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc83edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame restricted to kidney patients and columns of interest.\n",
    "ckdp = ckd.loc[\n",
    "    ckd['Class'] == 1,  # Kidney disease patients.\n",
    "     ['Serum Creatinine',  # Columns of interest.\n",
    "      'Blood Urea',\n",
    "      'Hemoglobin',\n",
    "      'White Blood Cell Count']]\n",
    "# Rename the columns with shortened names.\n",
    "ckdp.columns = ['Creatinine', 'Urea', 'Hemoglobin', 'WBC']\n",
    "ckdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cacb3b",
   "metadata": {},
   "source": [
    "First let us look at the relationship of the urea levels and the creatinine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckdp.plot.scatter('Urea', 'Creatinine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35dda79",
   "metadata": {},
   "source": [
    "There is a positive correlation between these sets of values; high urea and\n",
    "high creatinine go together; both reflect the failure of the kidneys to clear\n",
    "those substances from the blood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(ckdp, 'Urea', 'Creatinine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106eda8d",
   "metadata": {},
   "source": [
    "Now recall our standard method of finding a straight line to match these two\n",
    "attributes, where we choose our straight line to minimize the root mean squared\n",
    "error between the straight line prediction of the `Creatinine` values from the\n",
    "`Urea` values, and the actual values of `Creatinine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ee5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_any_line(c_s, x_values, y_values):\n",
    "    \"\"\" Root mean squared error for intercept, slope `c_s`\n",
    "    \"\"\"\n",
    "    c, s = c_s\n",
    "    predicted = c + x_values * s\n",
    "    error = y_values - predicted\n",
    "    return np.sqrt(np.mean(error ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dde784",
   "metadata": {},
   "source": [
    "We find the least-(root mean) squares straight line, using an initial guess for\n",
    "the slope and intercept of `[0, 0]`.\n",
    "\n",
    "Again we use the [Powell](https://en.wikipedia.org/wiki/Powell%27s_method)\n",
    "method to search for the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717eb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "min_res = minimize(rmse_any_line,\n",
    "                   initial_guess,\n",
    "                   args=(ckdp['Urea'], ckdp['Creatinine']),\n",
    "                   method='powell')\n",
    "min_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29d304",
   "metadata": {},
   "source": [
    "In particular, our intercept and slope are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee95e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06d7f5",
   "metadata": {},
   "source": [
    "You have already seen for this special case, of the root mean square (or the\n",
    "sum of squares) error, we can get the same answer directly with calculation. We\n",
    "used `linregress` from `scipy.stats` to do this calculation in earlier pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "linregress(ckdp['Urea'], ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d446b",
   "metadata": {},
   "source": [
    "Notice that the slope and the intercept are the same as those from `minimize`\n",
    "above, within the precision of the calculation, and that the `rvalue` above is\n",
    "the same as the correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(ckdp, 'Urea', 'Creatinine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e7969",
   "metadata": {},
   "source": [
    "## StatsModels\n",
    "\n",
    "Now it is time to introduce a major statistics package in Python,\n",
    "[StatsModels](https://www.statsmodels.org).\n",
    "\n",
    "StatsModels does many statistical calculations; among them are simple and\n",
    "multiple regression.  Statsmodels categorizes these types of simple linear\n",
    "models as \"ordinary least squares\" (OLS).\n",
    "\n",
    "Here we load the StatModels interface that uses Pandas data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Pandas interface to the StatsModels routines.\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06715dc1",
   "metadata": {},
   "source": [
    "Next we specify our model using a *formula*.  Read the `~` in the formula below\n",
    "as \"as a function of\".  So the formula specifies a linear (straight-line) model\n",
    "predicting `Creatinine` *as a function of* `Urea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ac9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = smf.ols(formula=\"Creatinine ~ Urea\", data=ckdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa702d7",
   "metadata": {},
   "source": [
    "Finally we *fit* the model, and show the summary of the model fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_fit = simple_model.fit()\n",
    "simple_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51469a1",
   "metadata": {},
   "source": [
    "Notice that the `coeff` column towards the bottom of this output.  Sure enough,\n",
    "StatsModels is doing the same calculation as `linregress`, and getting the same\n",
    "answer as `minimize` with our least-squares criterion.  The 'Intercept' and\n",
    "slope for 'Urea' are the same as those we have already seen with the other\n",
    "methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b3656",
   "metadata": {},
   "source": [
    "## Statsmodels where columns have spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc18e3e",
   "metadata": {},
   "source": [
    "As a side-note, you have to do some extra work to tell Statsmodels formulae\n",
    "about column names with spaces and other characters that would make the column\n",
    "names invalid as [variable names](Names.Rmd)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bdd78",
   "metadata": {},
   "source": [
    "For example, let's say we were using the original DataFrame `ckd`.  We want to use Statsmodels to find the best line to predict `'Serum Creatinine'` values from the `'Blood Urea'` values.  These were the original column names.  We could try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61608d8",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# This generates an error, because the Statsmodels formula interface\n",
    "# needs column names that work as variable names.\n",
    "another_model = smf.ols(formula=\"Serum Creatinine ~ Blood Urea\",\n",
    "                        data=ckd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a15e1",
   "metadata": {},
   "source": [
    "The solution is to use the `Q()`\n",
    "([Quote](https://patsy.readthedocs.io/en/latest/builtins-reference.html#patsy.builtins.Q))\n",
    "function in your formula.  It tells Statsmodels that you mean the words 'Serum'\n",
    "and 'Creatinine' to be one thing: 'Serum Creatinine' - the name of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f515ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = smf.ols(formula=\"Q('Serum Creatinine') ~ Q('Blood Urea')\", data=ckd)\n",
    "another_fit = another_model.fit()\n",
    "another_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727db529",
   "metadata": {},
   "source": [
    "## Multiple regression, in steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e5e88",
   "metadata": {},
   "source": [
    "Now we move on to trying to predict the `Creatinine` using the `Urea` *and* the\n",
    "`Hemoglobin`.  The `Urea` values and `Hemoglobin` values contain different\n",
    "information, so both values may be useful in predicting the `Creatinine`.\n",
    "\n",
    "One way to use both values is to use them step by step - first use `Urea`, and\n",
    "then use `Hemoglobin`.\n",
    "\n",
    "First we predict the `Creatinine` using just the straight-line relationship we\n",
    "have found for `Urea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d75693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the RMSE line; but all our methods gave the same line.\n",
    "intercept, slope = min_res.x\n",
    "creat_predicted = intercept + slope * ckdp['Urea']\n",
    "errors = ckdp['Creatinine'] - creat_predicted\n",
    "# Show the first five errors\n",
    "errors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a878318",
   "metadata": {},
   "source": [
    "The errors are the distances between the values predicted by the line, and the\n",
    "actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_errors(ckdp['Urea'], ckdp['Creatinine'], intercept, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550ec98",
   "metadata": {},
   "source": [
    "We can also call these errors *residuals* in the sense they are the error that\n",
    "*remains* after removing the (straight-line) effect of `Urea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6902a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also call the errors - residuals.\n",
    "residuals = errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855bad63",
   "metadata": {},
   "source": [
    "The remaining root mean square error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean square error\n",
    "np.sqrt(np.mean(residuals ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718c6ce",
   "metadata": {},
   "source": [
    "Now we want to see if we can predict these residuals with the `Hemoglobin`\n",
    "values.  Let's use these residuals as our new y values, and fit a predicting\n",
    "line using `Hemoglobin`.\n",
    "\n",
    "First plot the residuals (y) against the `Hemoglobin` (x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f73287",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ckdp['Hemoglobin'], residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141179f",
   "metadata": {},
   "source": [
    "Then fit a line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dfffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmse_hgb = minimize(rmse_any_line,\n",
    "                        initial_guess,\n",
    "                        args=(ckdp['Hemoglobin'], residuals),\n",
    "                        method='powell')\n",
    "min_rmse_hgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc5747",
   "metadata": {},
   "source": [
    "The results from minimize show that the line relating `Hemoglobin` and the\n",
    "residuals has a negative slope, as we would expect; more severe kidney disease\n",
    "leads to lower hemoglobin and higher creatinine.  The root mean square error\n",
    "has hardly changed, suggesting that `Hemoglobin` does not predict much, once we\n",
    "have allowed for the predictions using `Urea`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bdafc",
   "metadata": {},
   "source": [
    "## Multiple regression in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb098467",
   "metadata": {},
   "source": [
    "The other way to approach this problem is *multiple regression*.  In multiple\n",
    "regression, we use multiple columns of data *at the same time* to predict our\n",
    "measure of interest â€” in this case â€” the `Creatinine` values.\n",
    "\n",
    "In simple regression, we are using a single column of predicting values â€” in\n",
    "our case, the `Urea` values â€” to predict the measure of interest\n",
    "(`Creatinine`). We had to find the best *pair* of parameters â€” the intercept\n",
    "(call this `c`) and the slope for the single column of predicting values (call\n",
    "this `s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, s = min_res.x\n",
    "print('Intercept is', c)\n",
    "print('Slope is', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbfdddb",
   "metadata": {},
   "source": [
    "In multiple regression, we have more than one column of predicting values.  For\n",
    "each, we calculate a matching slope.  In our new case here, the two columns of\n",
    "predicting values are `Urea` and `Hemoglobin`.  We therefore have to find:\n",
    "\n",
    "* An intercept. Call this `c_m` to distinguish it from the intercept we found\n",
    "  in simple regression.\n",
    "* A slope for the line relating `Urea` to `Creatinine`.  Call this `s1`.\n",
    "* A slope for the line relating `Hemoglobin` to `Creatinine`.  Call this `s2`.\n",
    "\n",
    "In the simple regression case, we had to search many intercepts and many slopes\n",
    "to find the intercept, slope (`c, s`) pair, that gives the lowest cost function\n",
    "value.\n",
    "\n",
    "In our new case of multiple regression, we have to search many intercept, Urea\n",
    "slope and Creatinine slope *triplets* (`c_m, s1, s2`) to minimize the cost\n",
    "function.\n",
    "\n",
    "For the simple case, when predicting `Creatinine` from `Urea`, we got the\n",
    "predicted values by starting with the intercept `c`, then adding the result of\n",
    "multiplying the slope for `Urea` (`s`) by the `Urea` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_predictions = c + s * ckdp['Urea']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae98e1",
   "metadata": {},
   "source": [
    "The slope for Urea `s` gives the *scaled amount of Urea to add to the\n",
    "prediction*.\n",
    "\n",
    "When we have *two* predictors, `Urea` and `Hemoglobin`, we start with the intercept `c_m`, then add the result of multiplying the slope\n",
    "for `Urea` by the `Urea` values, and add the result of multiplying the slope\n",
    "for `Hemoglobin` by the `Hemoglobin` values.  The calculation is:\n",
    "\n",
    "* The new multiple regression intercept (`c_m`) plus\n",
    "* The `Urea` slope `s1` times `Urea` plus\n",
    "* The Hemoglobin slope times Hemoglobin:\n",
    "\n",
    "Let's make an initial guess at the three parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a840102",
   "metadata": {},
   "outputs": [],
   "source": [
    "guessed_c_m = 0\n",
    "guessed_s1 = 0.05\n",
    "guessed_s2 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed138b",
   "metadata": {},
   "source": [
    "The predictions are therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (guessed_c_m +\n",
    "               guessed_s1 * ckdp['Urea'] +\n",
    "               guessed_s2 * ckdp['Hemoglobin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd225d",
   "metadata": {},
   "source": [
    "The root mean square error for these three parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68048000",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ckdp['Creatinine'] - predictions\n",
    "# RMSE result\n",
    "np.sqrt(np.mean(errors ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199af2a",
   "metadata": {},
   "source": [
    "Here is a function to calculate the root mean squared error for these three parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d32fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_three_params(c_s_s, x1_values, x2_values, y_values):\n",
    "    c, s1, s2 = c_s_s\n",
    "    predictions = c + s1 * x1_values + s2 * x2_values\n",
    "    errors = y_values - predictions\n",
    "    return np.sqrt(np.mean(errors ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17c220",
   "metadata": {},
   "source": [
    "We repeat the RMSE calculation we did above, using the new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f68acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_three_params([guessed_c_m, guessed_s1, guessed_s2],\n",
    "                  ckdp['Urea'], ckdp['Hemoglobin'], ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfbd955",
   "metadata": {},
   "source": [
    "Here we calculate the root mean square error for an intercept of 1, and slopes\n",
    "for `Urea` and `Hemoglobin` of 0 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad49fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_three_params([1, 0, 0],\n",
    "                  ckdp['Urea'], ckdp['Hemoglobin'], ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908faa4",
   "metadata": {},
   "source": [
    "Now we can get `minimize` to find the intercept and two slopes that minimize the\n",
    "root mean square error (and the sum of squared error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac040179",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_css = minimize(rmse_three_params, [0, 0, 0], method='powell',\n",
    "                   args=(ckdp['Urea'],  # This will become x1_values above.\n",
    "                         ckdp['Hemoglobin'],  # This will become x2_values above.\n",
    "                         ckdp['Creatinine']  # This will become y_values above.\n",
    "                         ))\n",
    "min_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569156f",
   "metadata": {},
   "source": [
    "Just as for the simple regression case, and `linregress`, we can get our\n",
    "parameters by calculation directly, for this case where we are using\n",
    "least-squares as our criterion.\n",
    "\n",
    "Don't worry about the details of the function below.  It contains the matrix\n",
    "calculation to give us the same answer as `minimize` above, as long as we are\n",
    "minimizing the root mean square error (or sum of squared error) for an\n",
    "intercept and two slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_regression_triple(x1_values, x2_values, y_values):\n",
    "    \"\"\" linregress equivalent for intercept and two slopes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1_values: array-like, shape (n,)\n",
    "        First sequence (such as an array) of values to predict `y_values`.\n",
    "    x2_values: array-like, shape (n,)\n",
    "        First sequence (such as an array) of values to predict `y_values`.\n",
    "    y_values : array-like, shape (n,)\n",
    "        Values to be predicted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    params : array, shape (3,)\n",
    "        Least-squares fit parameters, where first parameter is intercept value,\n",
    "        second is slope for `x1_values`, and third is slope for `x2_values`.\n",
    "    \"\"\"\n",
    "    intercept_col = np.ones(len(y_values))\n",
    "    X = np.column_stack([intercept_col, x1_values, x2_values])\n",
    "    return np.linalg.pinv(X) @ y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b988e982",
   "metadata": {},
   "source": [
    "This function gives the same result as we got from `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e93d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = multiple_regression_triple(\n",
    "    ckdp['Urea'], ckdp['Hemoglobin'], # x values.\n",
    "    ckdp['Creatinine'])  # y values.\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa79603",
   "metadata": {},
   "source": [
    "Finally in this section, let's see StatsModels in action, to do the same\n",
    "calculation.\n",
    "\n",
    "Here we specify that we want to fit a linear model to `Creatinine` *as a\n",
    "function of* `Urea` *and* as a function of `Hemoglobin`.  This has the same\n",
    "meaning as above; that we will simultaneously fit the intercept, the `Urea`\n",
    "slope and the `Hemoglobin` slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96560099",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = smf.ols(formula=\"Creatinine ~ Urea + Hemoglobin\", data=ckdp)\n",
    "multi_fit = multi_model.fit()\n",
    "multi_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b15850",
   "metadata": {},
   "source": [
    "Notice again that StatsModels is doing the same calculation as above, and\n",
    "finding the same result as does `minimize`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cb7ea",
   "metadata": {},
   "source": [
    "## Multiple regression in 3D\n",
    "\n",
    "It can be useful to use a 3D plot to show what is going on here.  `minimize`\n",
    "and the other methods are finding these three parameters *simultaneously*:\n",
    "\n",
    "* An intercept;\n",
    "* A slope for `Urea`\n",
    "* A slope for `Hemoglobin`.\n",
    "\n",
    "The plot below shows what this looks like, in 3D.  Instead of the 2D case,\n",
    "where we are fitting the y data values (`Creatinine`) with a single straight\n",
    "line, here we are fitting the y data values with *two* straight lines.  In 3D\n",
    "these two straight lines form a plane, and we want the plane such that the sum\n",
    "of squares of the distance of the y values from the plane (plotted) is as small\n",
    "as possible.  `minimize` will change the intercept and the two slopes to move\n",
    "this plane around until it has minimized the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abac7a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "import mpl_toolkits.mplot3d  # (for Matplotlib < 3.2)\n",
    "ax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\n",
    "ax.scatter(ckdp['Urea'],\n",
    "           ckdp['Hemoglobin'],\n",
    "           ckdp['Creatinine']\n",
    "          )\n",
    "ax.set_xlabel('Urea')\n",
    "ax.set_ylabel('Hemoglobin')\n",
    "ax.set_zlabel('Creatinine')\n",
    "intercept, urea_slope, hgb_slope = min_css.x\n",
    "mx_urea, mx_hgb, mx_creat = 300, 16, 18\n",
    "ax.plot([0, mx_urea],\n",
    "        [intercept, intercept + urea_slope * mx_urea],\n",
    "        0,\n",
    "        zdir='y', color='blue', linestyle=':')\n",
    "mx_hgb = ckdp['Hemoglobin'].max()\n",
    "ax.plot([0, mx_hgb],\n",
    "        [intercept, intercept + hgb_slope * mx_hgb],\n",
    "        0,\n",
    "        zdir='x', color='black', linestyle=':')\n",
    "# Plot the fitting plane.\n",
    "plane_x = np.linspace(0, mx_urea, 50)\n",
    "plane_y = np.linspace(0, mx_hgb, 50)\n",
    "X, Y = np.meshgrid(plane_x, plane_y)\n",
    "Z = intercept + urea_slope * X + hgb_slope * Y\n",
    "ax.plot_surface(X, Y, Z, alpha=0.5)\n",
    "# Plot lines between each point and fitting plane\n",
    "for i, row in ckdp.iterrows():\n",
    "    x, y, actual = row['Urea'], row['Hemoglobin'], row['Creatinine']\n",
    "    fitted = intercept + x * urea_slope + y * hgb_slope\n",
    "    ax.plot([x, x], [y, y], [fitted, actual],\n",
    "            linestyle=':',\n",
    "            linewidth=0.5,\n",
    "            color='black')\n",
    "# Set the axis limits (and reverse y axis)\n",
    "ax.set_xlim(0, mx_urea)\n",
    "ax.set_ylim(mx_hgb, 0)\n",
    "ax.set_zlim(0, mx_creat);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894070c",
   "metadata": {},
   "source": [
    "## And even more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f653b87",
   "metadata": {},
   "source": [
    "At the top of this page, we started by finding two parameters:\n",
    "\n",
    "* intercept\n",
    "* slope for `Urea`\n",
    "\n",
    "Then we extended this to three parameters (two slopes):\n",
    "\n",
    "* intercept\n",
    "* slope for `Urea`\n",
    "* slope for `Hemoglobin`\n",
    "\n",
    "To get the predicted values for the three-parameter model we take\n",
    "\n",
    "* the intercept plus\n",
    "* the slope for `Urea` times the `Urea` values plus\n",
    "* the slope for `Hemoglobin` times the `Hemoglobin` values.\n",
    "\n",
    "In fact we can extend this idea further by adding more columns of values, and\n",
    "more slopes.  For example, imagine I want to be able to send a whole DataFrame of columns to the cost function, each with its matching slope, I could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0901de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_n_params(params, attributes, y_values):\n",
    "    \"\"\" RMSE for intercept, slopes model of `y_values` using `attributes`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array-like, shape (p + 1,)\n",
    "        Intercept (``params[0]``) and slopes ``params[1:]``, with one slope for each column in `attributes`.\n",
    "    attributes : pd.Dataframe, shape (n, p)\n",
    "        2D DataFrame, with one column per predicting parameter.\n",
    "    y_values : array-like, shape (n,)\n",
    "        1-dimensional array containing values to be predicted.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmse : float\n",
    "    Root mean squared error when predicting `y_values` from `c + params[1] *\n",
    "    attributes.iloc[:, 0] + params[2] * attributes.iloc[:,2] ...`\n",
    "    \"\"\"\n",
    "    c = params[0]  # The intercept\n",
    "    slopes = params[1:]  # One slope for each column in attributes.\n",
    "    predictions = c   # Start with intercept.\n",
    "    for col_no in np.arange(len(slopes)):\n",
    "        col = attributes.iloc[:, col_no]  # Get predictor.\n",
    "        col_contribution = slopes[col_no] * col  # Scale predictor.\n",
    "        predictions = predictions + col_contribution  # Add scaled predictor.\n",
    "    errors = y_values - predictions\n",
    "    return np.sqrt(np.mean(errors ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9023e61",
   "metadata": {},
   "source": [
    "First we show off the more general function by re-doing our two-parameter\n",
    "calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d292186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two columns of attributes\n",
    "attributes2 = ckdp.loc[:, ['Urea', 'Hemoglobin']]\n",
    "# Recalculate the RMSE\n",
    "rmse_n_params([1, 0, 0], attributes2, ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bdfc93",
   "metadata": {},
   "source": [
    "Using the more general function for the two-parameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_css = minimize(rmse_n_params, [1, 0, 0], method='powell',\n",
    "                   args=(attributes2, ckdp['Creatinine']))\n",
    "min_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b6f2e",
   "metadata": {},
   "source": [
    "We can add as many columns as we want, and ask `minimize` to find the best slopes for each column.  Here is the result with three columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb584939",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes3 = ckdp.loc[:, ['Urea', 'Hemoglobin', 'WBC']]\n",
    "min_css3 = minimize(rmse_n_params, [1, 0, 0, 0], method='powell',\n",
    "                    args=(attributes3, ckdp['Creatinine']))\n",
    "min_css3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b162d7",
   "metadata": {},
   "source": [
    "We can also generalize the mathematical calculation to solve the same problem,\n",
    "as long as we do want the best parameters for least-squares problems:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_regression_matrix(attributes, y_values):\n",
    "    \"\"\" linregress equivalent for multiple slopes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attributes : array-like, shape (n, p)\n",
    "        2-dimensional array-like (such as a DataFrame) where each column is a\n",
    "        regressor (covariate), to predict corresponding `y_values`.\n",
    "    y_values : array-like, shape (n,)\n",
    "        Values to be predicted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    params : array, shape (p + 1,)\n",
    "        Least-squares fit parameters, where first parameter is intercept value,\n",
    "        second is slope for first column in `attributes`, third is slope for\n",
    "        second column in `attributes`, and so on.\n",
    "    \"\"\"\n",
    "    intercept_col = np.ones(len(y_values))\n",
    "    X = np.column_stack([intercept_col, attributes])\n",
    "    return np.linalg.pinv(X) @ y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799dc87b",
   "metadata": {},
   "source": [
    "We get the same result from this calculation as we did from `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_regression_matrix(attributes3, ckdp['Creatinine'])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  },
  "orphan": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
