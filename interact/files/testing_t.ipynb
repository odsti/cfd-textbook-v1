{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0886b9df",
   "metadata": {},
   "source": [
    "# Testing the t test\n",
    "\n",
    "One of the great advantages of using simulation is that you can test the\n",
    "assertions your teachers make.\n",
    "\n",
    "For example, in the [permutation and t-test page](permutation_and_t_test), we asserted that the t-test is not\n",
    "valid when the underlying distribution of the numbers is not close to the\n",
    "[normal distribution](https://en.wikipedia.org/wiki/Normal_distribution).\n",
    "\n",
    "We can investigate this claim by simulating numbers from the null (ideal)\n",
    "world, and seeing what results we get from the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Make random number generator.\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d87b7a",
   "metadata": {},
   "source": [
    "The particular variant of the t-test that we were looking at in the page above\n",
    "was the *independent sample* t test for groups with similar variance.  Similar\n",
    "variance means that the distribution of the values in the first group is\n",
    "roughly equal to the distribution in the second group.\n",
    "\n",
    "For example, soon we will be testing again for a mean difference between the\n",
    "numbers of mosquitoes attracted to each of the 25 volunteers who drank beer,\n",
    "and the equivalent numbers for each of the 18 volunteers who drank water.\n",
    "\n",
    "See [the data\n",
    "page](https://github.com/matthew-brett/datasets/tree/master/mosquito_beer) for\n",
    "more details on the dataset, and [the data license page](data/LICENSE).\n",
    "\n",
    "For an equal variance test, we assume that the spread of the beer values is\n",
    "roughly equal to the spread of the water values, as measured by the *standard\n",
    "deviation*, or, equivalently, the *variance*.  Remember the variance is the\n",
    "squared standard deviation.\n",
    "\n",
    "We can pull together the code in [permutation and t-test\n",
    "page](permutation_and_t_test) to implement our own t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Scipy statistics routines.\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(group1, group2):\n",
    "    \"\"\" Independent sample t value and one-tail upper-tail p value.\n",
    "    \"\"\"\n",
    "    g1_mean = np.mean(group1)\n",
    "    g2_mean = np.mean(group2)\n",
    "    omd = g1_mean - g2_mean  # The observed mean difference.\n",
    "    errors = np.concatenate([group1 - g1_mean, group2 - g2_mean])\n",
    "    g1_n = len(group1)  # Number of observations in group1\n",
    "    g2_n = len(group2)  # Number of observations in group2\n",
    "    df = g1_n + g2_n - 2  # The \"degrees of freedom\".\n",
    "    estimated_sd = np.sqrt(np.sum(errors ** 2) / df)\n",
    "    t_stat = omd / (estimated_sd * np.sqrt(1 / g1_n + 1 / g2_n))\n",
    "    upper_tail_p = 1 - sps.t.cdf(t_stat, df)\n",
    "    return [t_stat, upper_tail_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db92f5",
   "metadata": {},
   "source": [
    "The only new thing in the implementation above is the second-to-last line,\n",
    "where we are using a routine in Scipy to calculate the probability value from\n",
    "the t statistic; the details of this are not important for our purpose.\n",
    "\n",
    "First we go back to the logic of this p value, which is very similar to the\n",
    "logic for permutation test p values:\n",
    "\n",
    "* Notice that the function calculates `omd = np.mean(group1) -\n",
    "  np.mean(group2)`. Call `omd` the *observed mean difference*.\n",
    "* Assume that we are in the null (ideal) world where the numbers from `group1`\n",
    "  and the numbers from `group2` have been drawn at random from the *same*\n",
    "  distribution.\n",
    "* The p value is the probability, in this null world, of seeing a mean\n",
    "  difference that is equal to or greater than the observed mean difference\n",
    "  `omd`.\n",
    "\n",
    "You can also think of a p value as an *index of surprise*.  The p value tells\n",
    "you how often you would expect to see an observed mean different this large, or\n",
    "larger, in the null (ideal) world.  If the p value is small, then the observed\n",
    "mean difference is surprising.  For example, if the p value is 0.05, it means\n",
    "that such difference only occurs 5% of the time by chance in the null world, or\n",
    "1 in 20 times.  You could say it was surprising at a 5% level.  Similarly a p\n",
    "value of 0.01 means the result would only occur 1% of the time in the null\n",
    "world, and it is surprising at a 1% level.\n",
    "\n",
    "Here we recreate the mosquito, beer, water data from the [permutation and\n",
    "t-test page](permutation_and_t_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_activated = np.array([14, 33, 27, 11, 12, 27, 26,\n",
    "                           25, 27, 27, 22, 36, 37,  3,\n",
    "                           23,  7, 25, 17, 36, 31, 30,\n",
    "                           22, 20, 29, 23])\n",
    "water_activated = np.array([33, 23, 23, 13, 24,  8,  4,\n",
    "                            21, 24, 21, 26, 27, 22, 21,\n",
    "                            25, 20,  7, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e605ef86",
   "metadata": {},
   "source": [
    "We run our t-test over these data to get the same result you saw in the\n",
    "[permtuation and t-test page](permutation_and_t_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = t_test(beer_activated, water_activated)\n",
    "print('t statistic:', t)\n",
    "print('Upper-tail p value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b45bb",
   "metadata": {},
   "source": [
    "To check our function is doing the correct calculation, we show that the t and\n",
    "p values are the same as the ones we get from using the standard Scipy function\n",
    "for independent t-tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a79a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sps.ttest_ind(beer_activated, water_activated)\n",
    "print('Scipy t statistic:', result.statistic)\n",
    "print('Scipy upper-tail p value:', result.pvalue / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3173b",
   "metadata": {},
   "source": [
    "Here is the observed difference in means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b29d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed mean difference\n",
    "np.mean(beer_activated) - np.mean(water_activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8851bc",
   "metadata": {},
   "source": [
    "The t-test p value above asserts that a difference in means as large as the\n",
    "observed difference, or larger, would only occur about 5% of the time in a null\n",
    "(ideal) world, where the beer and water values come from the same distribution.\n",
    "The observed result is surprising at around the 5% level.\n",
    "\n",
    "How would we check the assertion that the t-test is valid for normal\n",
    "distributions?\n",
    "\n",
    "If it is valid, then consider the situation where we do in fact draw two\n",
    "samples from *the same* normal distribution, and then ask the t test for a p\n",
    "value.  If the p value is 5%, it means that such a result should only occur by\n",
    "chance, in the null world, 5% of the time.\n",
    "\n",
    "So, we can repeat this procedure, drawing numbers that do in fact come from the\n",
    "null world, and check that the t-test only tells us that the result is\n",
    "surprising at the 5% level --- about 5% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "p_values = np.zeros(n_iters)  # Store the p values\n",
    "for i in np.arange(n_iters):\n",
    "    # Make 40 numbers from a normal distribution with mean 10, sd 2.\n",
    "    # These are our numbers from the null world.\n",
    "    randoms = rng.normal(10, 2, size=40)\n",
    "    # Split into two groups of size 20, and do a t-test.\n",
    "    t, p = t_test(randoms[:20], randoms[20:])\n",
    "    # Store the p value from the t-test.\n",
    "    p_values[i] = p\n",
    "# Show the first 5 p values.\n",
    "p_values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8f28e4",
   "metadata": {},
   "source": [
    "If the t-test calculation is correct, then we should only see a p value of 0.05\n",
    "or smaller about 5% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times the t-test said: surprising at 5% level.\n",
    "np.count_nonzero(p_values <= 0.05) / n_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bd290",
   "metadata": {},
   "source": [
    "Here the t-test is doing a good job --- it labels the result as surprising, at\n",
    "the 5% level, about 5% of the time.\n",
    "\n",
    "Now we ask - does it matter if the group sizes are unequal?  To test this, we\n",
    "do the same calculation, but split the numbers from the null world into one\n",
    "group of 3 and another of 37:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test working on unequal group sizes.\n",
    "p_values = np.zeros(n_iters)  # Store the p values\n",
    "for i in np.arange(n_iters):\n",
    "    # Make 40 numbers from a normal distribution with mean 10, sd 2.\n",
    "    randoms = rng.normal(10, 2, size=40)\n",
    "    # Split into two groups of size 3 and 37, and do a t-test.\n",
    "    t, p = t_test(randoms[:3], randoms[3:])\n",
    "    # Store the p value from the t-test.\n",
    "    p_values[i] = p\n",
    "# Show the first 5 p values.\n",
    "p_values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1e3c7",
   "metadata": {},
   "source": [
    "How good a job is it doing now, with unequal group sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e74296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times the t-test said: surprising at 5% level.\n",
    "# This time with unequal group sizes.\n",
    "np.count_nonzero(p_values <= 0.05) / n_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7585eb",
   "metadata": {},
   "source": [
    "The proportion is still around 5%, close to what it should be.\n",
    "\n",
    "What happens if we use a distribution other than the normal distribution?\n",
    "\n",
    "Here we use some random numbers from a [Chi-squared\n",
    "distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution).  The\n",
    "distribution looks like this, with a $k$ value of 2 (see the Wikipedia page):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6755c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_chi2_numbers = np.random.chisquare(2, size=1000)\n",
    "plt.hist(some_chi2_numbers)\n",
    "plt.title('1000 random samples from chi-squared distribution, k=2');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6cdea",
   "metadata": {},
   "source": [
    "We use this highly not-normal distribution to provide numbers to our t-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test working on unequal group sizes and not-normal distribution.\n",
    "p_values = np.zeros(n_iters)  # Store the p values\n",
    "for i in np.arange(n_iters):\n",
    "    # Make 40 numbers from a chi-squared distribution with k=2\n",
    "    randoms = np.random.chisquare(2, size=40)\n",
    "    # Split into two groups of size 3 and 37, and do a t-test.\n",
    "    t, p = t_test(randoms[:3], randoms[3:])\n",
    "    # Store the p value from the t-test.\n",
    "    p_values[i] = p\n",
    "# Show the first 5 p values.\n",
    "p_values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c54c5",
   "metadata": {},
   "source": [
    "In this situation the t-test starts to be less accurate - labeling too many\n",
    "random differences as being surprising at the 5% level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times the t-test said: surprising at 5% level.\n",
    "# This time with unequal group sizes.\n",
    "np.count_nonzero(p_values <= 0.05) / n_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970506f",
   "metadata": {},
   "source": [
    "Does a permutation test do a better job in this situation?\n",
    "\n",
    "We can test!\n",
    "\n",
    "Here is a function that does a permutation test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(group1, group2, niters=10000):\n",
    "    omd = np.mean(group1) - np.mean(group2)\n",
    "    g1_n = len(group1)\n",
    "    fake_mds = np.zeros(niters)\n",
    "    pooled = np.concatenate([group1, group2])\n",
    "    for i in np.arange(niters):\n",
    "        shuffled = rng.permutation(pooled)\n",
    "        fake_mds[i] = np.mean(shuffled[:g1_n]) - np.mean(shuffled[g1_n:])\n",
    "    return np.count_nonzero(fake_mds >= omd) / niters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276c7ac",
   "metadata": {},
   "source": [
    "Test this on the mosquito data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation(beer_activated, water_activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142769d",
   "metadata": {},
   "source": [
    "This is very similar to the t-statistic p value --- *for these data* that have\n",
    "fairly equal group size, and a distribution not far from normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ea1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test(beer_activated, water_activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc822d",
   "metadata": {},
   "source": [
    "Now let's check how the permutation test does when there are unequal group\n",
    "sizes and a not-normal distribution.\n",
    "\n",
    "The code below will take a few tens of seconds to run, because you are running\n",
    "many loops in the `permutation` function, each time you go through the main\n",
    "loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca344876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation working on unequal group sizes and not-normal distribution.\n",
    "# This is slow - do fewer iterations.\n",
    "n_iters = 1000\n",
    "p_values = np.zeros(n_iters)  # Store the p values\n",
    "for i in np.arange(n_iters):\n",
    "    # Make 40 numbers from a chi-squared distribution with k=2\n",
    "    randoms = np.random.chisquare(2, size=40)\n",
    "    # Split into two groups of size 3 and 37, and do a t-test.\n",
    "    # Use fewer iterations than usual to save computation time.\n",
    "    p = permutation(randoms[:3], randoms[3:], niters=1000)\n",
    "    # Store the p value from the permutation test.\n",
    "    p_values[i] = p\n",
    "# Show the first 5 p values.\n",
    "p_values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efe97c",
   "metadata": {},
   "source": [
    "How does the permutation test do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times the permutation test said: surprising at 5% level.\n",
    "# With unequal group sizes, not-normal distribution.\n",
    "np.count_nonzero(p_values <= 0.05) / n_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37a862",
   "metadata": {},
   "source": [
    "It is more accurate than the t-test.   In general the permutation method is\n",
    "more accurate for data from not-normal distributions, as well being accurate\n",
    "for normal distributions."
   ]
  }
 ],
 "metadata": {
  "jupyterbook": {
   "pre_code": "import numpy as _np; _np.random.seed(42)"
  },
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  },
  "orphan": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
