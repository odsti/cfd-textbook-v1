{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366bdb4a",
   "metadata": {},
   "source": [
    "# Noble politics and comparing counts\n",
    "\n",
    "This page has two aims:\n",
    "\n",
    "* to practice and extend [Pandas indexing](pandas_indexing);\n",
    "* to extend the idea of permutation to data in categories;\n",
    "\n",
    "We also ask the question - is politics noble?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553cf74",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Our usual imports\n",
    "import numpy as np\n",
    "# Make random number generator.\n",
    "rng = np.random.default_rng()\n",
    "import pandas as pd\n",
    "# Safe setting for Pandas.  Needs Pandas version >= 1.5.\n",
    "pd.set_option('mode.copy_on_write', True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6516e54",
   "metadata": {},
   "source": [
    "Our data is from this book:\n",
    "\n",
    "> Samuel P. Oliner and Pearl M. Oliner (1988) \"The Altruistic Personality:\n",
    "> Rescuers of Jews in Nazi Europe\". Free Press, New York.\n",
    "\n",
    "See [the dataset page](https://github.com/odsti/datasets/tree/master/oliner1988)\n",
    "for some more details.\n",
    "\n",
    "The Oliners wanted to identify distinctive traits of people who rescued Jews in\n",
    "Nazi Europe.  In order to do that, they collected structured interviews with\n",
    "231 people for whom there was strong documentary evidence that they had\n",
    "sheltered Jews, despite considerable risk to themselves. These are the\n",
    "\"rescuer\" group in the table below.  They also found 126 controls with roughly\n",
    "similar background, nationality, age and education. Of these, 53 claimed to\n",
    "have either sheltered Jews, or to have been active in the resistance.  These\n",
    "are the \"actives\" group in the table.  This leaves 73 controls who were not\n",
    "active, and the authors termed these \"bystanders\".\n",
    "\n",
    "The table below has data from table 6.8 of their book, where they break down\n",
    "the groups according to the answer they gave to the question \"Did you belong to\n",
    "a political party before the war?\".\n",
    "\n",
    "As usual, if you are running on your own computers, download the file\n",
    "{download}`oliner_tab6_8a_1.csv <data/oliner_tab6_8a_1.csv>` to the same\n",
    "directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table\n",
    "party_tab = pd.read_csv('data/oliner_tab6_8a_1.csv')\n",
    "party_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d88ca0",
   "metadata": {},
   "source": [
    "## Setting the index\n",
    "\n",
    "We have already seen [Pandas indexing](pandas_indexing).   We are going to be\n",
    "selecting data out of this table with indexing, and we would like to make the\n",
    "index (row labels) be as informative as possible.  The current index, which\n",
    "Pandas created automatically, is sequential numbers, which are not memorable or\n",
    "informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9be05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_tab.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa546a3",
   "metadata": {},
   "source": [
    "Row labels need not be numbers.  They can also be strings.  Strings are often\n",
    "more useful in identifying the data in the rows.\n",
    "\n",
    "We might prefer to use the values in the first column - `party_yn` as the\n",
    "labels for the rows.\n",
    "\n",
    "We can do this with the data frame `set_index` method.  It replaces the current\n",
    "index (the sequential numbers) with the data from a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d15137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the numerical index with the party_yn labels.\n",
    "party_tab = party_tab.set_index('party_yn')\n",
    "party_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ea6f3",
   "metadata": {},
   "source": [
    "Notice that Pandas took the `party_yn` column out of the data frame and used it\n",
    "to replace the index.\n",
    "\n",
    "This makes it easier to use the `.loc` attribute to select data, using row\n",
    "labels.  For example, we can select individual elements like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rescuers were there, in total?\n",
    "party_tab.loc['out of', 'rescuer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835ae87",
   "metadata": {},
   "source": [
    "## The question\n",
    "\n",
    "Looking at the data in the table, it seems as if the Rescuers had a stronger\n",
    "tendency to belong to a political party than, say, the Bystanders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed3d4d",
   "metadata": {},
   "source": [
    "To get more specific, we look at the proportion of Rescuers and Bystanders that\n",
    "answered Yes (to being a member of a political party before the war).\n",
    "\n",
    "The `out of` row has the total number of people in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of Yes for Rescuers.\n",
    "party_tab.loc['Yes', 'rescuer'] / party_tab.loc['out of', 'rescuer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c619c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of Yes for Bystanders.\n",
    "party_tab.loc['Yes', 'bystander'] / party_tab.loc['out of', 'bystander']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc39d2",
   "metadata": {},
   "source": [
    "That looks like a substantial difference - but could it have come about by\n",
    "chance?\n",
    "\n",
    "Let's put that another way - we see that 44 of 209 Rescuers have \"Yes\" to\n",
    "belonging to political party.  Is 44 a larger number than we would expect by\n",
    "chance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d9bf6",
   "metadata": {},
   "source": [
    "## Cleaning up the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8a49d",
   "metadata": {},
   "source": [
    "We start by selecting the data we need from the original table.\n",
    "\n",
    "First we use `loc` indexing to specify that we want:\n",
    "\n",
    "* The rows labeled \"No\" and \"Yes\";\n",
    "* The columns labeled \"bystander\" and \"rescuer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6aca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "bystander_tab = party_tab.loc[['No', 'Yes'], ['bystander', 'rescuer']]\n",
    "bystander_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d5bcf",
   "metadata": {},
   "source": [
    "**For reflection**: You could do the same operation with the `.drop` method.\n",
    "How?\n",
    "\n",
    "Notice the *lists* above `['Yes', 'No']` and `['bystander', 'rescuer']`. These\n",
    "specify the row labels and columns labels that we want.\n",
    "\n",
    "Notice too that we have swapped the order of the rows (to \"No\" and \"Yes\" ) and\n",
    "the columns (to \"bystander\" and \"rescuer\").  This is to better match the\n",
    "output of `pd.crosstab` below.  You may see what we mean when we get there.\n",
    "\n",
    "Now we ask you to cast your eye to the bottom-right value of the table, and\n",
    "the value of interest â€” 44.  This is the count for people who were both\n",
    "\"rescuer\" and said \"Yes\" to political party.  We continue our search to see if\n",
    "this value is larger than we would expect by chance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fabe99",
   "metadata": {},
   "source": [
    "## What do we mean by chance?\n",
    "\n",
    "Our question above was whether the observed proportions in the table could have\n",
    "come about by chance.   As usual, our first step is to imagine an ideal (null)\n",
    "world where rescuers and bystanders have exactly the same tendency to belong to\n",
    "a political party.  This is the null-model, often called the null hypothesis.\n",
    "\n",
    "We will take random samples from this world, to see if the random samples look\n",
    "anything like the numbers we see in the actual data.  If they do, then we might\n",
    "not be very interested in the differences we see, in the actual data, because\n",
    "the differences could plausibly have come about as a sample from an ideal world\n",
    "where there was no difference in tendency to belong to political parties.\n",
    "\n",
    "So, how do we take samples from this ideal world?\n",
    "\n",
    "We will take the same number of fake rescuers as there are real rescuers, and\n",
    "the same number of fake bystanders as there are real bystanders.\n",
    "\n",
    "We will assume that the same number of people overall are _not_ members of a\n",
    "political party:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people who did not belong to a political party.\n",
    "n_no = bystander_tab.loc['No', 'rescuer'] + bystander_tab.loc['No', 'bystander']\n",
    "n_no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8c7ae",
   "metadata": {},
   "source": [
    "This leaves the rest, who _were_ a member of a political party:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people who did belong to a political party.\n",
    "n_yes = bystander_tab.loc['Yes', 'rescuer'] + bystander_tab.loc['Yes', 'bystander']\n",
    "n_yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea36481",
   "metadata": {},
   "source": [
    "We can get the same numbers for \"Yes\" and \"No\" using the `sum` method of the\n",
    "data frame, with the `axis=1` argument, to tell sum to operate along the\n",
    "columns (the second axis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55828b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_totals = bystander_tab.sum(axis=1)\n",
    "row_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9070b46",
   "metadata": {},
   "source": [
    "The total number of people represented in the table is the sum of the \"Yes\" and\n",
    "\"No\" counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_totals.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c36f42",
   "metadata": {},
   "source": [
    "We therefore have 280 labels (51 Yes labels and 229 No labels) to assign to our\n",
    "280 people (209 rescuers and 71 bystanders).\n",
    "\n",
    "In our ideal world, this assignment to \"Yes\" and \"No\" is random.   We can\n",
    "shuffle up the labels (\"Yes\", \"No\"), and assign each person (rescuer,\n",
    "bystander) a shuffled (therefore, random) label.  We take this fake pairing,\n",
    "and calculate the numbers in each of the four categories, to create a fake\n",
    "table, that is a random version of the actual table.  If we do that many times,\n",
    "we can get an idea of how the numbers vary in the fake tables, and therefore,\n",
    "what randomness looks like, in this ideal world, of no association between\n",
    "rescuer / bystander and Yes / No.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227e947",
   "metadata": {},
   "source": [
    "## Recreating the original data\n",
    "\n",
    "The `bystander_tab` table above gives the counts of people in each of the four\n",
    "categories.  We will call this the Counts Table.\n",
    "\n",
    "To do the shuffling we need, we reconstruct a new `people` table that has one\n",
    "row for each person represented in the Counts Table.  We could also call this\n",
    "the Observations Table.  Instead of having the counts, it reconstructs the\n",
    "individual entries that correspond to the counts.\n",
    "\n",
    "There are 280 people represented in the Counts Table, of which:\n",
    "\n",
    "* 64 are \"No\" for party membership and \"bystander\" for respondent type: (\"No\",\n",
    "  \"bystander) label pair.\n",
    "* 165 are (\"No\", \"rescuer\")\n",
    "* 7 are \"Yes\" for party and \"bystander\" for respondent (\"Yes\", \"bystander\")\n",
    "* 44 are (\"Yes\", \"rescuer\")\n",
    "\n",
    "Let's say that the `people` DataFrame has two columns, one for each label that can apply to a person.\n",
    "\n",
    "The first column is `party_yn` and contains the \"Yes\" or \"No\" according to\n",
    "whether that person was a member of a political party.\n",
    "\n",
    "The second column is `respondent` and contains `bystander` if the person was a\n",
    "bystander, and `rescuer` if they were a rescuer.\n",
    "\n",
    "The `people` DataFrame would have:\n",
    "\n",
    "* 64 rows with \"No\" in `party_yn` and \"bystander\" in `respondent`;\n",
    "* 165 rows with \"No\" in `party_yn` and \"rescuer\" in `respondent`;\n",
    "* 7 rows with \"Yes\" in `party_yn` and \"bystander\" in `respondent`;\n",
    "* 44 rows with \"Yes\" in `party_yn` and \"rescuer\" in `respondent`;\n",
    "\n",
    "Our approach will be to make a DataFrame that contains all four possible label\n",
    "pairs, and then repeat each of the rows by their respective counts (64, 165, 7,\n",
    "44)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c8c2b",
   "metadata": {},
   "source": [
    "the DataFrame with the four possible label pairs.\n",
    "\n",
    "We will do that using a *list of lists*.\n",
    "\n",
    "Here is a list with the first label pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_pair = ['No', 'bystander']\n",
    "first_label_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d5555",
   "metadata": {},
   "source": [
    "We want to make a DataFrame that starts with 64 of these pairs.  We can do this using the `pd.DataFrame` constructor with a *list of lists*.  For example, here we make a new DataFrame with two *rows*,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1887d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_two_pairs = [first_label_pair, first_label_pair]\n",
    "first_two_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_two_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c648818",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_two_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c80dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_two_pairs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663776ef",
   "metadata": {},
   "source": [
    "In fact we can make multiple copies of a list by using the multiply (`*`) operator, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd066844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply on a list means 'replicate'.\n",
    "my_list = [1, 2]\n",
    "my_list * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_list = [99]\n",
    "another_list * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52e993",
   "metadata": {},
   "source": [
    "Notice that multiply (`*`) behaves completely differently for *arrays*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply on an array means elementwise multiplication.\n",
    "my_array = np.array([1, 2])\n",
    "my_array * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5563a04",
   "metadata": {},
   "source": [
    "Now we can replicate the initial pair with a list of lists and multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_three_pairs = [first_label_pair] * 3\n",
    "first_three_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fbf57",
   "metadata": {},
   "source": [
    "The reason this is useful, is that we can then use the `pd.DataFrame` constructor to convert the list of lists into rows of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aeb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a list of lists to define first three rows of DataFrame\n",
    "first_three_rows = pd.DataFrame(first_three_pairs)\n",
    "first_three_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412fb2e",
   "metadata": {},
   "source": [
    "With that simple call, the DataFrame has default column labels of 0 and 1.  We\n",
    "can specify more useful and memorable column labels with the `columns=`\n",
    "argument to the `pd.DataFrame` constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fff2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_three_rows = pd.DataFrame(first_three_pairs,\n",
    "                                columns=['party_yn', 'respondent'])\n",
    "first_three_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445be4ad",
   "metadata": {},
   "source": [
    "We want our new *observations* DataFrame to start with 64 observations.  Remember, 64 is the count for the label combination of 'No', 'bystander':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dff21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bystander_tab.loc['No', 'bystander']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bystander_row_list = [['No', 'bystander']] * 64\n",
    "# Show the first 5 lists in the list of lists\n",
    "no_bystander_row_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64580c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists into a DataFrame\n",
    "no_bystander_observations = pd.DataFrame(\n",
    "    no_bystander_row_list,\n",
    "    columns=['party_yn', 'bystander'])\n",
    "no_bystander_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d38c48",
   "metadata": {},
   "source": [
    "How do we add the next 165 rows, with label pair 'No', 'rescuer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba52e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bystander_tab.loc['No', 'rescuer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe8b253",
   "metadata": {},
   "source": [
    "We first make the list of lists corresponding to the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rescuer_row_list = [['No', 'rescuer']] * 165\n",
    "# Show the first 5 lists in the list of lists.\n",
    "no_rescuer_row_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f4c521",
   "metadata": {},
   "source": [
    "Next we use another aspect of lists - *addition*.  As multiplication of a list replicates the elements in the list, so addition appends the elements of one list to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891face7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of two lists appends the second list to the first.\n",
    "my_list = [1, 2]\n",
    "another_list = [99, 100]\n",
    "my_list + another_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f486b1",
   "metadata": {},
   "source": [
    "Remember, this is different from addition with *arrays*, which does elementwise addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cea06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of two arrays gives elementwise addition.\n",
    "my_array = np.array([1, 2])\n",
    "another_array = np.array([99, 100])\n",
    "my_array + another_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da4ca5",
   "metadata": {},
   "source": [
    "If we *add* the first list of lists to the second list of lists, we get the 64 + 165 lists, and therefore, 64 + 165 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_no_row_list = no_bystander_row_list + no_rescuer_row_list\n",
    "len(both_no_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_no_observations = pd.DataFrame(both_no_row_list,\n",
    "                                   columns=['party_yn', 'respondent'])\n",
    "both_no_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac47c4",
   "metadata": {},
   "source": [
    "Let's assemble the whole observations DataFrame in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_lists = (\n",
    "    # The No rows\n",
    "    [['No', 'bystander']] * bystander_tab.loc['No', 'bystander'] +\n",
    "    [['No', 'rescuer']] * bystander_tab.loc['No', 'rescuer'] +\n",
    "    # The Yes rows\n",
    "    [['Yes', 'bystander']] * bystander_tab.loc['Yes', 'bystander'] +\n",
    "    [['Yes', 'rescuer']] * bystander_tab.loc['Yes', 'rescuer']\n",
    ")\n",
    "len(row_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 5 lists:\n",
    "row_lists[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last 5 lists\n",
    "row_lists[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba9a06",
   "metadata": {},
   "source": [
    "Now we can construct the observations DataFrame from the list of lists that define the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8300a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the rows for \"party_yn\" and \"bystander\" by repeating rows from pairs.\n",
    "people = pd.DataFrame(row_lists,\n",
    "                      columns=['party_yn', 'respondent'])\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e01fbd8",
   "metadata": {},
   "source": [
    "We check the counts in the `people` data frame by doing some row selection. For\n",
    "example, to check we really do have 64 rows with the label \"No\" in `party_yn`\n",
    "and \"bystander\" in `respondent`, we could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90eb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rows = people[people['party_yn'] == 'No']\n",
    "no_bystander_rows = no_rows[no_rows['respondent'] == 'bystander']\n",
    "len(no_bystander_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b69012",
   "metadata": {},
   "source": [
    "Luckily, Pandas has a `crosstab` function that does this counting work for us,\n",
    "for all four combinations of \"Yes\", \"No\" and \"bystander\", \"rescuer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf45e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_tab = pd.crosstab(people['party_yn'], people['respondent'])\n",
    "people_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b774043",
   "metadata": {},
   "source": [
    "As we hoped, the `pd.crosstab` on the `people` data frame regenerates the\n",
    "counts Table we started with.\n",
    "\n",
    "We have used `pd.crosstab` to reconstruct the Counts Table from our\n",
    "Observations Table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2537da9",
   "metadata": {},
   "source": [
    "## The null world\n",
    "\n",
    "The null or ideal world for our question is a world where the pairing of the\n",
    "`party_yn` \"Yes\" / \"No\" labels and the `respondent` \"bystander\" / \"rescuer\"\n",
    "labels are random.\n",
    "\n",
    "We can make a data frame from that world doing a random shuffle of the\n",
    "`party_yn` labels in our Observations Table, so the pairing of the `party_yn`\n",
    "and `respondent` labels is random.\n",
    "\n",
    "First pull out the `party_yn` and `respondent` columns for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb846232",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_yn = people['party_yn']\n",
    "respondent = people['respondent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61da64a",
   "metadata": {},
   "source": [
    "Remember, the crosstab of these columns gives the original count table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ecc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(party_yn, respondent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac8da9",
   "metadata": {},
   "source": [
    "Next, shuffle the `party_yn` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_party = rng.permutation(party_yn)\n",
    "# Show the first ten values\n",
    "shuffled_party[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65d9e9",
   "metadata": {},
   "source": [
    "Show the new shuffled `party_yn` values with the original respondent labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_people = pd.DataFrame()\n",
    "fake_people['party_yn'] = shuffled_party\n",
    "fake_people['respondent'] = respondent\n",
    "fake_people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7092c1c",
   "metadata": {},
   "source": [
    "By the way â€” we only care about the random pairing between `party_yn` and\n",
    "`respondent`.  We shuffled `party_yn` above, but we could instead have shuffled\n",
    "`respondent`, or both; any of these would generate a random pairing.\n",
    "\n",
    "We now need the counts of people in each category.  That is we need counts for:\n",
    "\n",
    "* 'No' paired with 'bystander'\n",
    "* 'Yes' paired with 'bystander'\n",
    "* 'No' paired with 'rescuer'\n",
    "* 'Yes' paired with 'rescuer'\n",
    "\n",
    "For example, remember we are particularly interested in the combination of\n",
    "\"Yes\" and \"rescuer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fe1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tab = pd.crosstab(shuffled_party, respondent)\n",
    "fake_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797662",
   "metadata": {},
   "source": [
    "We saw in the original data that the rescuers seemed to have a greater tendency\n",
    "to belong to a political party.  Let us restrict our attention to the count of\n",
    "\"Yes\" and \"rescuer\".\n",
    "\n",
    "That count, in our original Counts Table, was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_y_resc = bystander_tab.loc['Yes', 'rescuer']\n",
    "actual_y_resc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19927173",
   "metadata": {},
   "source": [
    "The equivalent count in our new fake Counts Table is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_y_resc = fake_tab.loc['Yes', 'rescuer']\n",
    "fake_y_resc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d5a75",
   "metadata": {},
   "source": [
    "We need more random samples to see if the fake value is often as large as the\n",
    "real value.  If so, then the ideal world, where the association between \"Yes\" /\n",
    "\"No, and \"bystander\" / \"rescuer\" is random, is a reasonable explanation of what\n",
    "we see in the real world, and we might not want to investigate these data much\n",
    "further.\n",
    "\n",
    "Unfortunately, `pd.crosstab` is horribly slow, so we need to drop our usual\n",
    "number of iterations to 1000 to keep the run-time down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1382be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(1000)\n",
    "for i in np.arange(1000):\n",
    "    # Make a fake Observations Table by shuffling one set of labels.\n",
    "    shuffled_party = rng.permutation(party_yn)\n",
    "    # Get the Counts Table from the fake Observations Table.\n",
    "    fake_tab = pd.crosstab(shuffled_party, respondent)\n",
    "    # Store the count of interest.\n",
    "    counts[i] = fake_tab.loc['Yes', 'rescuer']\n",
    "# Show the first 10 counts.\n",
    "counts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39c167",
   "metadata": {},
   "source": [
    "Here is our *sampling distribution* from sampling in the ideal world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(counts);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ed763",
   "metadata": {},
   "source": [
    "How unusual is the actual value, in this ideal world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8675a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times we see ideal world sample >= actual value.\n",
    "p_lte = np.count_nonzero(counts >= actual_y_resc) / len(counts)\n",
    "p_lte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db3c2b",
   "metadata": {},
   "source": [
    "## Very similar to Fisher's exact test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2a3cb",
   "metadata": {},
   "source": [
    "The Fisher's exact test is the test that Fisher invented for the [Lady Tasting\n",
    "Tea](fishers_tea.Rmd) problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c958f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a301975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative='greater' actually refers to the probability that a sampling\n",
    "# distribution top-left value will be greater than or equal to the observed\n",
    "# top-left value, but for reasons given below, this is the same as the test\n",
    "# on the bottom-right value, that we are interested in.\n",
    "odds_ratio, p_val = sps.fisher_exact(bystander_tab, alternative='greater')\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6549a",
   "metadata": {},
   "source": [
    "## Like the Chi-squared test\n",
    "\n",
    "Another common test for this sort of situation is the [Chi-squared\n",
    "test](https://en.wikipedia.org/wiki/Chi-squared_test).\n",
    "\n",
    "The Chi-squared test tests the table values against the null hypothesis that\n",
    "there is no (null, not-any) tendency for (in our case) the Party membership\n",
    "labels to differ between the Rescuer and Bystander groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adaec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Chi-squared test, without Yates correction for 2x2 tables.\n",
    "chi2_val, p_val, degf, expected = sps.chi2_contingency(people_tab,\n",
    "                                                       correction=False)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439fb03",
   "metadata": {},
   "source": [
    "The Chi-squared test is asking a slightly different question from our original\n",
    "test.   Our original test was a *one-tailed* test, in the sense that it has a\n",
    "*direction*.  We are specifically interested in whether the null-world\n",
    "generates values *as low as* 44, but we were not interested in whether the\n",
    "null-world generates values that are *greater* than those we would expect by\n",
    "chance.  The Chi-squared test is against a null-world where there is no\n",
    "deviation from random association *in either direction*.  Hence the\n",
    "*not-directional* Chi-squared test has a higher probability than our\n",
    "*directional* randomization test, because we have to allow for chance\n",
    "deviations in either direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953430b",
   "metadata": {},
   "source": [
    "## A question for reflection\n",
    "\n",
    "Now look at this.  Here I do the same test, but I am looking at both of these\n",
    "counts, for each trial:\n",
    "\n",
    "* \"Yes\", \"rescuer\".\n",
    "* \"No\", \"bystander\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34160d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, rescuer\n",
    "counts_y_resc = np.zeros(1000)\n",
    "# No, rescuer\n",
    "counts_n_by = np.zeros(1000)\n",
    "for i in np.arange(1000):\n",
    "    # Make a fake Observations Table by shuffling one set of labels.\n",
    "    shuffled_party = rng.permutation(party_yn)\n",
    "    fake_data = people.copy()\n",
    "    fake_data['party_yn'] = shuffled_party\n",
    "    # Get the Counts Table from the fake Observations Table.\n",
    "    fake_tab = pd.crosstab(fake_data['party_yn'], fake_data['respondent'])\n",
    "    # Store the \"Yes\" / \"rescuer\" count.\n",
    "    counts_y_resc[i] = fake_tab.loc['Yes', 'rescuer']\n",
    "    # Also store the \"No\" / \"bystander\" count.\n",
    "    counts_n_by[i] = fake_tab.loc['No', 'bystander']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e16aba",
   "metadata": {},
   "source": [
    "Here are the values of the \"Yes\" / \"rescuer\" counts for the first 10 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ten Yes rescuer counts\n",
    "counts_y_resc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed3e9d",
   "metadata": {},
   "source": [
    "These are the corresponding \"No\" / \"bystander\" counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ten No bystander counts\n",
    "counts_n_by[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3200e3",
   "metadata": {},
   "source": [
    "You may notice that they go up and down in exactly the same way.  When the\n",
    "\"Yes\" / \"rescuer\" count goes up or down by 1, so does the \"No\" / \"bystander\"\n",
    "count - and the same is true for any change in the values; +1, +2, +3 ..., -1,\n",
    "-2, -3 ...\n",
    "\n",
    "Therefore, the *difference* between the counts on each trial is always the\n",
    "same.  In our case, the difference is -20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a629325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference between the counts for each trial is always the same.\n",
    "count_diff = counts_y_resc - counts_n_by\n",
    "print('First 10 differences', count_diff[:10])\n",
    "print(\"Differences all the same?\")\n",
    "np.all(count_diff == count_diff[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac301c3",
   "metadata": {},
   "source": [
    "If we know the \"Yes\" / \"rescuer\" value, we can get the corresponding \"No\" /\n",
    "\"bystander\" value by subtracting -20 (in our particular case).\n",
    "\n",
    "This means that if we calculate the corresponding p values for the \"Yes\" /\n",
    "\"rescuer\" or \"No\" / \"bystander\" counts, they are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times we see ideal world sample >= actual value.\n",
    "p_lte_y_resc = np.count_nonzero(counts_y_resc >= actual_y_resc) / len(counts)\n",
    "p_lte_y_resc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced269e3",
   "metadata": {},
   "source": [
    "The test for \"No\", \"bystander\" follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a41ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of times we see ideal world sample >= actual value.\n",
    "actual_n_by = bystander_tab.loc['No', 'bystander']\n",
    "p_lte_n_by = np.count_nonzero(counts_n_by >= actual_n_by) / len(counts)\n",
    "p_lte_n_by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa644d",
   "metadata": {},
   "source": [
    "See if you can work out why these counts go up and down in exactly the same\n",
    "way, on each trial.  Why does this mean that the p values must be the same?\n",
    "\n",
    "After a little reflection, have a look at the [2 by 2\n",
    "tables](two_by_two_tables) page."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
