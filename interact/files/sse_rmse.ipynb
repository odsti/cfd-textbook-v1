{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d806a7f",
   "metadata": {},
   "source": [
    "# Sum of squares, root mean square\n",
    "\n",
    "The [mean and slopes page](mean_and_slopes) used the Sum of Squared Error (SSE)\n",
    "as the measure of how well a particular slope fits the data.\n",
    "\n",
    "Here we will think about another, derived measure, called the Root Mean Square Error.\n",
    "\n",
    "First, let us go back to the original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbf142",
   "metadata": {},
   "source": [
    "## Hemoglobin and Packed Cell Volume, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Make plots look a little bit more fancy\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Print to 4 decimal places, show tiny values as 0\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import pandas as pd\n",
    "pd.set_option('mode.copy_on_write', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ab5e4",
   "metadata": {},
   "source": [
    "We go back to the [data on chronic kidney\n",
    "disease](data/chronic_kidney_disease).\n",
    "\n",
    "Download the data to your computer via this link: {download}`ckd_clean.csv\n",
    "<data/ckd_clean.csv>`.\n",
    "\n",
    "We were interested to find the \"best\" slope for a line that relates the blood\n",
    "hemoglobin measures in each patient, with their corresponding Packed Cell\n",
    "Volume (PCV) blood measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ad574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "ckd = pd.read_csv('data/ckd_clean.csv')\n",
    "hgb = np.array(ckd['Hemoglobin'])\n",
    "pcv = np.array(ckd['Packed Cell Volume'])\n",
    "# Plot HGB on the x axis, PCV on the y axis\n",
    "plt.plot(hgb, pcv, 'o')\n",
    "plt.xlabel('Hemoglobin concentration')\n",
    "plt.ylabel('Packed cell volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a3f7f",
   "metadata": {},
   "source": [
    "We are assuming our line goes through `hgb == 0` and `pcv == 0`, on the basis\n",
    "that the red blood cells measured by PCV contain all the hemoglobin, so if PCV\n",
    "is 0 then hemoglobin must be 0 and vice versa.  Our *predicted* values for PCV\n",
    "for each patient are the given by some slope`s` multiplied by the corresponding\n",
    "hemoglobin value for that patient.\n",
    "\n",
    "For example, say the slope is 2.25, then the predicted PCV values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 2.25\n",
    "predicted_pcv = s * hgb\n",
    "predicted_pcv[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31040101",
   "metadata": {},
   "source": [
    "The *errors* for these predictions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ace2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pcv - predicted_pcv\n",
    "errors[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fba7f",
   "metadata": {},
   "source": [
    "## Sum of Squared error\n",
    "\n",
    "We decided to use the Sum of Squared Error (SSE) as a measure of the quality of\n",
    "fit.\n",
    "\n",
    "The sum of squared error is nothing but:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = np.sum(errors ** 2)\n",
    "sse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5dad",
   "metadata": {},
   "source": [
    "Here's a function to return the SSE.  We call this the *cost function* because\n",
    "it calculates a *cost* in terms of error for a given slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sse(slope):\n",
    "    predicted_pcv = hgb * slope  # 'hgb' comes from the top level\n",
    "    errors = pcv - predicted_pcv # 'pcv' comes from the top level\n",
    "    return np.sum(errors ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate SSE for slope of interest.\n",
    "calc_sse(2.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9201cf8",
   "metadata": {},
   "source": [
    "Then we used `minimize` to find the slope that minimizes the SSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3be433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "# 2.25 below is the slope value to start the search.\n",
    "res_sse = minimize(calc_sse, 2.25)\n",
    "res_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47c09d",
   "metadata": {},
   "source": [
    "Notice the warning - there was some inaccuracy in the calculation.   We  may try slightly different cost functions to avoid that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edc998",
   "metadata": {},
   "source": [
    "## Root mean squared error\n",
    "\n",
    "One problem with the SSE is that it can get very large, especially if there are\n",
    "a large number of points.  When the values get large, this can cause\n",
    "calculation problems.  Very large numbers for SSE can make\n",
    "it harder to think about the SSE values.\n",
    "\n",
    "One way of allowing for the number of points, is to use the *mean* square error\n",
    "(MSE), instead of the SSE.  Here is the MSE cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21976eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(slope):\n",
    "    predicted_pcv = hgb * slope  # 'hgb' comes from the top level\n",
    "    errors = pcv - predicted_pcv # 'pcv' comes from the top level\n",
    "    return np.mean(errors ** 2)  # Notice mean instead of sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8b288",
   "metadata": {},
   "source": [
    "We try `minimize` again, to find the best slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.25 below is the slope value to start the search.\n",
    "res_mse = minimize(calc_mse, 2.25)\n",
    "res_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01868dc",
   "metadata": {},
   "source": [
    "Notice there is no warning this time in the optimization message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873ac82",
   "metadata": {},
   "source": [
    "Notice that running `minimize` on the MSE found the same slope as it did for\n",
    "the SSE. The resulting cost function `fun` value is the original SSE value\n",
    "divided by the number of points. (It's not exactly the same because of the\n",
    "inaccuracy of the SSE estimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sse.fun / len(hgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93365d0",
   "metadata": {},
   "source": [
    "It's also common to use the *square root* of the MSE, or the Root Mean Square\n",
    "Error.  This has one advantage that it's easier to compare the RMSE to the\n",
    "individual errors — we don't normally think easily in terms of squared error.\n",
    "This is the RMSE cost function — another tiny variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520266a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(slope):\n",
    "    predicted_pcv = hgb * slope  # 'hgb' comes from the top level\n",
    "    errors = pcv - predicted_pcv # 'pcv' comes from the top level\n",
    "    return np.sqrt(np.mean(errors ** 2))  # Notice square root of mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.25 below is the slope value to start the search.\n",
    "res_rmse = minimize(calc_rmse, 2.25)\n",
    "res_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bf2622",
   "metadata": {},
   "source": [
    "The cost function `fun` value is just the square root of the MSE `fun` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733332b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(res_mse.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3f631",
   "metadata": {},
   "source": [
    "Notice again that `minimize` on RMSE found exactly the same slope as for MSE and SSE.   Why?\n",
    "\n",
    "Reflect a little, and then read on.\n",
    "\n",
    "(monotonicity)="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cdf48c",
   "metadata": {},
   "source": [
    "## Monotonicity\n",
    "\n",
    "SSE, MSE, and RMSE give the same parameters from `minimize` because they are\n",
    "*monotonic* with respect to each other.  Put another way, the SSE and the RMSE\n",
    "have a monotonic relationship.  Put yet another way,\n",
    "the RMSE is a [monotonic\n",
    "function](https://en.wikipedia.org/wiki/Monotonic_function) of the SSE.\n",
    "\n",
    "Remember, the Root Mean Square Error (RMSE) is just the square root of the Mean\n",
    "Square Error (MSE), and the MSE is the Sum of Squared Error (SSE) divided by\n",
    "the number of values in the x array (which is the same as the number of values\n",
    "in the y array).\n",
    "\n",
    "For example, imagine we have the following set of SSE values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d99e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slopes = 10000\n",
    "some_slopes = np.linspace(2, 4, n_slopes)\n",
    "SSEs = np.zeros(n_slopes)\n",
    "for i in np.arange(n_slopes):\n",
    "    SSEs[i] = calc_sse(some_slopes[i])\n",
    "\n",
    "plt.scatter(some_slopes, SSEs)\n",
    "plt.xlabel('Slope')\n",
    "plt.xlabel('SSE')\n",
    "plt.title('SSE as a function of slope');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf0f7a",
   "metadata": {},
   "source": [
    "We can calculate the matching MSE values by dividing by `n` (the number of\n",
    "`hgb` or `pcv` values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2675b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(hgb)\n",
    "MSEs = SSEs / n  # Corresponding Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca643c",
   "metadata": {},
   "source": [
    "When we plot the MSE values as a function of (y-axis) the SSE values (x axis),\n",
    "we see that there is a straight line relationship, as we would expect, with a\n",
    "slope of `1 / n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9603c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(SSEs, MSEs)\n",
    "plt.xlabel('SSE values')\n",
    "plt.ylabel('Corresponding MSE values')\n",
    "plt.title('MSE as a function of SSE');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f2bee",
   "metadata": {},
   "source": [
    "This straight line relationship is one example of a *strictly increasing*\n",
    "monotonic relationship.\n",
    "\n",
    "Consider any two SSE values, call these `S1` and `S2`.  There are corresponding\n",
    "MSE values `M1` and `M2` (in fact given by `S1 / n` and `S2 / n`).  The\n",
    "relationship between SSE and MSE is strictly increasing monotonic because, for\n",
    "any values `S1` and `S2`:\n",
    "\n",
    "* when `S1 > S2` then it is also true that`M1 > M2`\n",
    "* when `S1 < S2` then `M1 < M2`.\n",
    "* when `S1 == S2`, `M1 == M2`.\n",
    "\n",
    "You can see that relationship in the plot above, because MSE always goes up, as\n",
    "SSE goes up.\n",
    "\n",
    "The same is true of the RMSE values as a function of the SSE values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEs = np.sqrt(MSEs)  # Corresponding Root Mean Square Error\n",
    "plt.scatter(SSEs, RMSEs)\n",
    "plt.xlabel('SSE values')\n",
    "plt.ylabel('Corresponding RMSE values')\n",
    "plt.title('RMSE as a function of SSE');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43027282",
   "metadata": {},
   "source": [
    "Notice, again, that the RMSE always goes up as SSE goes up.\n",
    "\n",
    "Now consider `minimize`.  It is looking at the parameters to minimize the value\n",
    "for  — say - SSE.  But, you can probably see from the argument above, that if\n",
    "we found the parameters to minimize SSE, those must also be the parameters to\n",
    "minimize MSE, and to minimize RMSE, because once we have found the smallest\n",
    "SSE, that must also be the smallest MSE or RMSE.\n",
    "\n",
    "Therefore, we can minimize on the RMSE, and we are\n",
    "guaranteed to get the same parameters, within calculation precision, as we\n",
    "would if we had minimized on the SSE or the MSE.\n",
    "\n",
    "In the rest of these textbook pages, we will nearly always use RMSE, because\n",
    "it's a common metric, and one that is relatively easy to interpret as a typical\n",
    "error for single point."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
